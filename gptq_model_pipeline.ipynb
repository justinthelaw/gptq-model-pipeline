{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOYAjKWxbBGZxHKCbQjfPR2"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6RLySGwfm0Ff",
        "outputId": "318f0459-02b3-42d0-acc8-5652654e7230"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: transformers 4.43.3\n",
            "Uninstalling transformers-4.43.3:\n",
            "  Successfully uninstalled transformers-4.43.3\n",
            "Found existing installation: torch 2.4.0\n",
            "Uninstalling torch-2.4.0:\n",
            "  Successfully uninstalled torch-2.4.0\n",
            "Found existing installation: datasets 2.20.0\n",
            "Uninstalling datasets-2.20.0:\n",
            "  Successfully uninstalled datasets-2.20.0\n",
            "Collecting torch\n",
            "  Using cached torch-2.4.0-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Collecting datasets\n",
            "  Using cached datasets-2.20.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.5.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (3.0.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.82)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.7.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Using cached torch-2.4.0-cp310-cp310-manylinux1_x86_64.whl (797.2 MB)\n",
            "Using cached datasets-2.20.0-py3-none-any.whl (547 kB)\n",
            "Installing collected packages: torch, datasets\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "auto-gptq 0.7.1 requires transformers>=4.31.0, which is not installed.\n",
            "auto-round 0.2 requires transformers, which is not installed.\n",
            "peft 0.12.0 requires transformers, which is not installed.\n",
            "fastai 2.7.15 requires torch<2.4,>=1.10, but you have torch 2.4.0 which is incompatible.\n",
            "torchaudio 2.3.1+cu121 requires torch==2.3.1, but you have torch 2.4.0 which is incompatible.\n",
            "torchvision 0.18.1+cu121 requires torch==2.3.1, but you have torch 2.4.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-2.20.0 torch-2.4.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch",
                  "torchgen"
                ]
              },
              "id": "1d53678f29d442b992087303d7ef9fe0"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# uninstall existing dependencies\n",
        "!pip uninstall transformers torch datasets -y\n",
        "\n",
        "# install GPTQModel pre-reqs\n",
        "!pip install torch datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# clone GPTQModel repo\n",
        "!git clone https://github.com/ModelCloud/GPTQModel.git\n",
        "\n",
        "# compile and install GPTQModel\n",
        "# You can optionally include specific modules like vllm, sglang, or bitblas by adding them in brackets. Example: pip install -vvv --no-build-isolation .[vllm,sglang,bitblas]\n",
        "!cd GPTQModel && pip install -vvv --no-build-isolation ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmjJmv-RnY_k",
        "outputId": "e8b13bbf-6951-478e-b2af-3c79dcc10b0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'GPTQModel'...\n",
            "remote: Enumerating objects: 7359, done.\u001b[K\n",
            "remote: Counting objects: 100% (1531/1531), done.\u001b[K\n",
            "remote: Compressing objects: 100% (680/680), done.\u001b[K\n",
            "remote: Total 7359 (delta 978), reused 937 (delta 849), pack-reused 5828\u001b[K\n",
            "Receiving objects: 100% (7359/7359), 8.96 MiB | 12.88 MiB/s, done.\n",
            "Resolving deltas: 100% (5078/5078), done.\n",
            "Using pip 24.1.2 from /usr/local/lib/python3.10/dist-packages/pip (python 3.10)\n",
            "Non-user install because site-packages writeable\n",
            "Created temporary directory: /tmp/pip-build-tracker-9247o59h\n",
            "Initialized build tracking at /tmp/pip-build-tracker-9247o59h\n",
            "Created build tracker: /tmp/pip-build-tracker-9247o59h\n",
            "Entered build tracker: /tmp/pip-build-tracker-9247o59h\n",
            "Created temporary directory: /tmp/pip-install-e6a13lbu\n",
            "Created temporary directory: /tmp/pip-ephem-wheel-cache-f7wyzpcf\n",
            "Processing /content/GPTQModel\n",
            "  Added file:///content/GPTQModel to build tracker '/tmp/pip-build-tracker-9247o59h'\n",
            "  Running setup.py (path:/content/GPTQModel/setup.py) egg_info for package from file:///content/GPTQModel\n",
            "  Created temporary directory: /tmp/pip-pip-egg-info-4bux2s23\n",
            "  Running command python setup.py egg_info\n",
            "  Requirement already satisfied: accelerate>=0.31.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (0.32.1)\n",
            "  Requirement already satisfied: datasets>=2.20.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (2.20.0)\n",
            "  Collecting sentencepiece>=0.2.0 (from -r requirements.txt (line 3))\n",
            "    Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "  Requirement already satisfied: numpy>=1.26.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (1.26.4)\n",
            "  Collecting rouge>=1.0.1 (from -r requirements.txt (line 5))\n",
            "    Downloading rouge-1.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
            "  Collecting gekko>=1.1.1 (from -r requirements.txt (line 6))\n",
            "    Downloading gekko-1.2.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "  Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (2.4.0)\n",
            "  Requirement already satisfied: triton>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (3.0.0)\n",
            "  Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (0.4.3)\n",
            "  Collecting transformers>=4.43.3 (from -r requirements.txt (line 10))\n",
            "    Downloading transformers-4.43.3-py3-none-any.whl.metadata (43 kB)\n",
            "       ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 43.7/43.7 kB 1.6 MB/s eta 0:00:00\n",
            "  Requirement already satisfied: tqdm>=4.66.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (4.66.4)\n",
            "  Requirement already satisfied: threadpoolctl>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (3.5.0)\n",
            "  Requirement already satisfied: packaging>=24.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (24.1)\n",
            "  Collecting ninja>=1.11.1.1 (from -r requirements.txt (line 14))\n",
            "    Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (5.3 kB)\n",
            "  Collecting protobuf>=4.25.3 (from -r requirements.txt (line 15))\n",
            "    Downloading protobuf-5.27.2-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "  Collecting intel_extension_for_transformers>=1.4.2 (from -r requirements.txt (line 16))\n",
            "    Downloading intel_extension_for_transformers-1.4.2-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (26 kB)\n",
            "  Collecting auto-round==0.2 (from -r requirements.txt (line 17))\n",
            "    Downloading auto_round-0.2-py3-none-any.whl.metadata (17 kB)\n",
            "  Collecting huggingface-hub>=0.24.2 (from -r requirements.txt (line 18))\n",
            "    Downloading huggingface_hub-0.24.3-py3-none-any.whl.metadata (13 kB)\n",
            "  Collecting auto-gptq (from auto-round==0.2->-r requirements.txt (line 17))\n",
            "    Downloading auto_gptq-0.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "  Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from auto-round==0.2->-r requirements.txt (line 17)) (9.0.0)\n",
            "  Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.31.0->-r requirements.txt (line 1)) (5.9.5)\n",
            "  Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.31.0->-r requirements.txt (line 1)) (6.0.1)\n",
            "  Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.20.0->-r requirements.txt (line 2)) (3.15.4)\n",
            "  Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.20.0->-r requirements.txt (line 2)) (17.0.0)\n",
            "  Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.20.0->-r requirements.txt (line 2)) (0.6)\n",
            "  Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.20.0->-r requirements.txt (line 2)) (0.3.8)\n",
            "  Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.20.0->-r requirements.txt (line 2)) (2.1.4)\n",
            "  Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.20.0->-r requirements.txt (line 2)) (2.32.3)\n",
            "  Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.20.0->-r requirements.txt (line 2)) (3.4.1)\n",
            "  Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets>=2.20.0->-r requirements.txt (line 2)) (0.70.16)\n",
            "  Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets>=2.20.0->-r requirements.txt (line 2)) (2024.5.0)\n",
            "  Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.20.0->-r requirements.txt (line 2)) (3.9.5)\n",
            "  Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge>=1.0.1->-r requirements.txt (line 5)) (1.16.0)\n",
            "  Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->-r requirements.txt (line 7)) (4.12.2)\n",
            "  Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->-r requirements.txt (line 7)) (1.13.1)\n",
            "  Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->-r requirements.txt (line 7)) (3.3)\n",
            "  Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->-r requirements.txt (line 7)) (3.1.4)\n",
            "  Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->-r requirements.txt (line 7)) (12.1.105)\n",
            "  Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->-r requirements.txt (line 7)) (12.1.105)\n",
            "  Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->-r requirements.txt (line 7)) (12.1.105)\n",
            "  Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->-r requirements.txt (line 7)) (9.1.0.70)\n",
            "  Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->-r requirements.txt (line 7)) (12.1.3.1)\n",
            "  Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->-r requirements.txt (line 7)) (11.0.2.54)\n",
            "  Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->-r requirements.txt (line 7)) (10.3.2.106)\n",
            "  Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->-r requirements.txt (line 7)) (11.4.5.107)\n",
            "  Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->-r requirements.txt (line 7)) (12.1.0.106)\n",
            "  Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->-r requirements.txt (line 7)) (2.20.5)\n",
            "  Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->-r requirements.txt (line 7)) (12.1.105)\n",
            "  Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0.0->-r requirements.txt (line 7)) (12.5.82)\n",
            "  Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.43.3->-r requirements.txt (line 10)) (2024.5.15)\n",
            "  Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.43.3->-r requirements.txt (line 10)) (0.19.1)\n",
            "  Collecting schema (from intel_extension_for_transformers>=1.4.2->-r requirements.txt (line 16))\n",
            "    Downloading schema-0.7.7-py2.py3-none-any.whl.metadata (34 kB)\n",
            "  Collecting neural-compressor (from intel_extension_for_transformers>=1.4.2->-r requirements.txt (line 16))\n",
            "    Downloading neural_compressor-2.6-py3-none-any.whl.metadata (15 kB)\n",
            "  Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.20.0->-r requirements.txt (line 2)) (1.3.1)\n",
            "  Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.20.0->-r requirements.txt (line 2)) (23.2.0)\n",
            "  Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.20.0->-r requirements.txt (line 2)) (1.4.1)\n",
            "  Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.20.0->-r requirements.txt (line 2)) (6.0.5)\n",
            "  Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.20.0->-r requirements.txt (line 2)) (1.9.4)\n",
            "  Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.20.0->-r requirements.txt (line 2)) (4.0.3)\n",
            "  Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.20.0->-r requirements.txt (line 2)) (3.3.2)\n",
            "  Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.20.0->-r requirements.txt (line 2)) (3.7)\n",
            "  Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.20.0->-r requirements.txt (line 2)) (2.0.7)\n",
            "  Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.20.0->-r requirements.txt (line 2)) (2024.7.4)\n",
            "  Collecting peft>=0.5.0 (from auto-gptq->auto-round==0.2->-r requirements.txt (line 17))\n",
            "    Downloading peft-0.12.0-py3-none-any.whl.metadata (13 kB)\n",
            "  Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.0->-r requirements.txt (line 7)) (2.1.5)\n",
            "  Collecting deprecated>=1.2.13 (from neural-compressor->intel_extension_for_transformers>=1.4.2->-r requirements.txt (line 16))\n",
            "    Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
            "  Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from neural-compressor->intel_extension_for_transformers>=1.4.2->-r requirements.txt (line 16)) (4.10.0.84)\n",
            "  Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from neural-compressor->intel_extension_for_transformers>=1.4.2->-r requirements.txt (line 16)) (9.4.0)\n",
            "  Requirement already satisfied: prettytable in /usr/local/lib/python3.10/dist-packages (from neural-compressor->intel_extension_for_transformers>=1.4.2->-r requirements.txt (line 16)) (3.10.2)\n",
            "  Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from neural-compressor->intel_extension_for_transformers>=1.4.2->-r requirements.txt (line 16)) (1.3.2)\n",
            "  Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from neural-compressor->intel_extension_for_transformers>=1.4.2->-r requirements.txt (line 16)) (2.0.8)\n",
            "  Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.20.0->-r requirements.txt (line 2)) (2.8.2)\n",
            "  Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.20.0->-r requirements.txt (line 2)) (2024.1)\n",
            "  Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.20.0->-r requirements.txt (line 2)) (2024.1)\n",
            "  Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.0.0->-r requirements.txt (line 7)) (1.3.0)\n",
            "  Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.13->neural-compressor->intel_extension_for_transformers>=1.4.2->-r requirements.txt (line 16)) (1.14.1)\n",
            "  Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prettytable->neural-compressor->intel_extension_for_transformers>=1.4.2->-r requirements.txt (line 16)) (0.2.13)\n",
            "  Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pycocotools->neural-compressor->intel_extension_for_transformers>=1.4.2->-r requirements.txt (line 16)) (3.7.1)\n",
            "  Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->neural-compressor->intel_extension_for_transformers>=1.4.2->-r requirements.txt (line 16)) (1.13.1)\n",
            "  Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->neural-compressor->intel_extension_for_transformers>=1.4.2->-r requirements.txt (line 16)) (1.4.2)\n",
            "  Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor->intel_extension_for_transformers>=1.4.2->-r requirements.txt (line 16)) (1.2.1)\n",
            "  Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor->intel_extension_for_transformers>=1.4.2->-r requirements.txt (line 16)) (0.12.1)\n",
            "  Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor->intel_extension_for_transformers>=1.4.2->-r requirements.txt (line 16)) (4.53.1)\n",
            "  Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor->intel_extension_for_transformers>=1.4.2->-r requirements.txt (line 16)) (1.4.5)\n",
            "  Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor->intel_extension_for_transformers>=1.4.2->-r requirements.txt (line 16)) (3.1.2)\n",
            "  Downloading auto_round-0.2-py3-none-any.whl (66 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 66.0/66.0 kB 5.1 MB/s eta 0:00:00\n",
            "  Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 23.2 MB/s eta 0:00:00\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "  Downloading gekko-1.2.1-py3-none-any.whl (13.2 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13.2/13.2 MB 80.8 MB/s eta 0:00:00\n",
            "  Downloading transformers-4.43.3-py3-none-any.whl (9.4 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9.4/9.4 MB 90.7 MB/s eta 0:00:00\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 307.2/307.2 kB 24.5 MB/s eta 0:00:00\n",
            "  Downloading protobuf-5.27.2-cp38-abi3-manylinux2014_x86_64.whl (309 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 309.3/309.3 kB 22.9 MB/s eta 0:00:00\n",
            "  Downloading intel_extension_for_transformers-1.4.2-cp310-cp310-manylinux_2_28_x86_64.whl (45.3 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 45.3/45.3 MB 10.2 MB/s eta 0:00:00\n",
            "  Downloading huggingface_hub-0.24.3-py3-none-any.whl (417 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 417.3/417.3 kB 22.9 MB/s eta 0:00:00\n",
            "  Downloading auto_gptq-0.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23.5 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 23.5/23.5 MB 46.8 MB/s eta 0:00:00\n",
            "  Downloading neural_compressor-2.6-py3-none-any.whl (1.5 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.5/1.5 MB 44.4 MB/s eta 0:00:00\n",
            "  Downloading schema-0.7.7-py2.py3-none-any.whl (18 kB)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "  Downloading peft-0.12.0-py3-none-any.whl (296 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 296.4/296.4 kB 18.9 MB/s eta 0:00:00\n",
            "  Installing collected packages: sentencepiece, schema, ninja, rouge, protobuf, gekko, deprecated, huggingface-hub, transformers, neural-compressor, peft, intel_extension_for_transformers, auto-gptq, auto-round\n",
            "    Attempting uninstall: sentencepiece\n",
            "      Found existing installation: sentencepiece 0.1.99\n",
            "      Uninstalling sentencepiece-0.1.99:\n",
            "        Successfully uninstalled sentencepiece-0.1.99\n",
            "    Attempting uninstall: protobuf\n",
            "      Found existing installation: protobuf 3.20.3\n",
            "      Uninstalling protobuf-3.20.3:\n",
            "        Successfully uninstalled protobuf-3.20.3\n",
            "    Attempting uninstall: huggingface-hub\n",
            "      Found existing installation: huggingface-hub 0.23.5\n",
            "      Uninstalling huggingface-hub-0.23.5:\n",
            "        Successfully uninstalled huggingface-hub-0.23.5\n",
            "  ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "  cudf-cu12 24.4.1 requires protobuf<5,>=3.20, but you have protobuf 5.27.2 which is incompatible.\n",
            "  cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n",
            "  google-ai-generativelanguage 0.6.6 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.2 which is incompatible.\n",
            "  google-cloud-aiplatform 1.59.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.2 which is incompatible.\n",
            "  google-cloud-bigquery-storage 2.25.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.2 which is incompatible.\n",
            "  google-cloud-datastore 2.19.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.2 which is incompatible.\n",
            "  google-cloud-firestore 2.16.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.2 which is incompatible.\n",
            "  tensorflow 2.15.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.27.2 which is incompatible.\n",
            "  tensorflow-metadata 1.15.0 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 5.27.2 which is incompatible.\n",
            "  Successfully installed auto-gptq-0.7.1 auto-round-0.2 deprecated-1.2.14 gekko-1.2.1 huggingface-hub-0.24.3 intel_extension_for_transformers-1.4.2 neural-compressor-2.6 ninja-1.11.1.1 peft-0.12.0 protobuf-5.27.2 rouge-1.0.1 schema-0.7.7 sentencepiece-0.2.0 transformers-4.43.3\n",
            "  Traceback (most recent call last):\n",
            "    File \"<string>\", line 2, in <module>\n",
            "    File \"<pip-setuptools-caller>\", line 34, in <module>\n",
            "    File \"/content/GPTQModel/setup.py\", line 82, in <module>\n",
            "      raise EnvironmentError(\n",
            "  OSError: GPTQModel requires at least one GPU device with CUDA compute capability >= `6.0`.\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  \u001b[1;35mfull command\u001b[0m: \u001b[34m/usr/bin/python3 -c '\u001b[0m\n",
            "\u001b[34m  exec(compile('\"'\"''\"'\"''\"'\"'\u001b[0m\n",
            "\u001b[34m  # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py\u001b[0m\n",
            "\u001b[34m  #\u001b[0m\n",
            "\u001b[34m  # - It imports setuptools before invoking setup.py, to enable projects that directly\u001b[0m\n",
            "\u001b[34m  #   import from `distutils.core` to work with newer packaging standards.\u001b[0m\n",
            "\u001b[34m  # - It provides a clear error message when setuptools is not installed.\u001b[0m\n",
            "\u001b[34m  # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so\u001b[0m\n",
            "\u001b[34m  #   setuptools doesn'\"'\"'t think the script is `-c`. This avoids the following warning:\u001b[0m\n",
            "\u001b[34m  #     manifest_maker: standard file '\"'\"'-c'\"'\"' not found\".\u001b[0m\n",
            "\u001b[34m  # - It generates a shim setup.py, for handling setup.cfg-only projects.\u001b[0m\n",
            "\u001b[34m  import os, sys, tokenize\u001b[0m\n",
            "\u001b[34m  \u001b[0m\n",
            "\u001b[34m  try:\u001b[0m\n",
            "\u001b[34m      import setuptools\u001b[0m\n",
            "\u001b[34m  except ImportError as error:\u001b[0m\n",
            "\u001b[34m      print(\u001b[0m\n",
            "\u001b[34m          \"ERROR: Can not execute `setup.py` since setuptools is not available in \"\u001b[0m\n",
            "\u001b[34m          \"the build environment.\",\u001b[0m\n",
            "\u001b[34m          file=sys.stderr,\u001b[0m\n",
            "\u001b[34m      )\u001b[0m\n",
            "\u001b[34m      sys.exit(1)\u001b[0m\n",
            "\u001b[34m  \u001b[0m\n",
            "\u001b[34m  __file__ = %r\u001b[0m\n",
            "\u001b[34m  sys.argv[0] = __file__\u001b[0m\n",
            "\u001b[34m  \u001b[0m\n",
            "\u001b[34m  if os.path.exists(__file__):\u001b[0m\n",
            "\u001b[34m      filename = __file__\u001b[0m\n",
            "\u001b[34m      with tokenize.open(__file__) as f:\u001b[0m\n",
            "\u001b[34m          setup_py_code = f.read()\u001b[0m\n",
            "\u001b[34m  else:\u001b[0m\n",
            "\u001b[34m      filename = \"<auto-generated setuptools caller>\"\u001b[0m\n",
            "\u001b[34m      setup_py_code = \"from setuptools import setup; setup()\"\u001b[0m\n",
            "\u001b[34m  \u001b[0m\n",
            "\u001b[34m  exec(compile(setup_py_code, filename, \"exec\"))\u001b[0m\n",
            "\u001b[34m  '\"'\"''\"'\"''\"'\"' % ('\"'\"'/content/GPTQModel/setup.py'\"'\"',), \"<pip-setuptools-caller>\", \"exec\"))' egg_info --egg-base /tmp/pip-pip-egg-info-4bux2s23\u001b[0m\n",
            "  \u001b[1;35mcwd\u001b[0m: /content/GPTQModel/\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "Exception information:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/build/metadata_legacy.py\", line 64, in generate_metadata\n",
            "    call_subprocess(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/subprocess.py\", line 209, in call_subprocess\n",
            "    raise error\n",
            "pip._internal.exceptions.InstallationSubprocessError: python setup.py egg_info exited with 1\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 179, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/req_command.py\", line 67, in wrapper\n",
            "    return func(self, options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 377, in run\n",
            "    requirement_set = resolver.resolve(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 76, in resolve\n",
            "    collected = self.factory.collect_root_requirements(root_reqs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 538, in collect_root_requirements\n",
            "    reqs = list(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 494, in _make_requirements_from_install_req\n",
            "    cand = self._make_base_candidate_from_link(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 231, in _make_base_candidate_from_link\n",
            "    self._link_candidate_cache[link] = LinkCandidate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 303, in __init__\n",
            "    super().__init__(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 158, in __init__\n",
            "    self.dist = self._prepare()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 235, in _prepare\n",
            "    dist = self._prepare_distribution()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 314, in _prepare_distribution\n",
            "    return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/prepare.py\", line 527, in prepare_linked_requirement\n",
            "    return self._prepare_linked_requirement(req, parallel_builds)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/prepare.py\", line 642, in _prepare_linked_requirement\n",
            "    dist = _get_prepared_distribution(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/prepare.py\", line 72, in _get_prepared_distribution\n",
            "    abstract_dist.prepare_distribution_metadata(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/distributions/sdist.py\", line 69, in prepare_distribution_metadata\n",
            "    self.req.prepare_metadata()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/req/req_install.py\", line 580, in prepare_metadata\n",
            "    self.metadata_directory = generate_metadata_legacy(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/build/metadata_legacy.py\", line 71, in generate_metadata\n",
            "    raise MetadataGenerationFailed(package_details=details) from error\n",
            "pip._internal.exceptions.MetadataGenerationFailed: metadata generation failed\n",
            "Removed file:///content/GPTQModel from build tracker '/tmp/pip-build-tracker-9247o59h'\n",
            "Removed build tracker: '/tmp/pip-build-tracker-9247o59h'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from gptqmodel import GPTQModel, QuantizeConfig\n",
        "from transformers import AutoTokenizer\n",
        "from datasets import load_dataset\n",
        "\n",
        "pretrained_model_id = \"microsoft/Phi-3-mini-128k-instruct\"\n",
        "quantized_model_id = \"Phi-3-mini-128k-instruct-4bit-128g\"\n",
        "\n",
        "def get_wikitext2(tokenizer, nsamples, seqlen):\n",
        "    traindata = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\", split=\"train\").filter(\n",
        "        lambda x: len(x[\"text\"]) >= seqlen)\n",
        "\n",
        "    return [tokenizer(example[\"text\"]) for example in traindata.select(range(nsamples))]\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def calculate_avg_ppl(model, tokenizer):\n",
        "    from gptqmodel.utils import Perplexity\n",
        "\n",
        "    ppl = Perplexity(\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        dataset_path=\"wikitext\",\n",
        "        dataset_name=\"wikitext-2-raw-v1\",\n",
        "        split=\"train\",\n",
        "        text_column=\"text\",\n",
        "    )\n",
        "\n",
        "    all = ppl.calculate(n_ctx=512, n_batch=512)\n",
        "\n",
        "    # average ppl\n",
        "    avg = sum(all) / len(all)\n",
        "\n",
        "    return avg\n",
        "\n",
        "def main():\n",
        "    tokenizer = AutoTokenizer.from_pretrained(pretrained_model_id, use_fast=True)\n",
        "\n",
        "    traindataset = get_wikitext2(tokenizer, nsamples=256, seqlen=1024)\n",
        "\n",
        "    quantize_config = QuantizeConfig(\n",
        "        bits=4,  # quantize model to 4-bit\n",
        "        group_size=128,  # it is recommended to set the value to 128\n",
        "    )\n",
        "\n",
        "    # load un-quantized model, the model will always be force loaded into cpu\n",
        "    model = GPTQModel.from_pretrained(pretrained_model_id, quantize_config)\n",
        "\n",
        "    # quantize model, the calibration_dataset should be list of dict whose keys can only be \"input_ids\" and \"attention_mask\"\n",
        "    # with value under torch.LongTensor type.\n",
        "    model.quantize(traindataset)\n",
        "\n",
        "    # save quantized model\n",
        "    model.save_quantized(quantized_model_id)\n",
        "\n",
        "    # save quantized model using safetensors\n",
        "    model.save_quantized(quantized_model_id, use_safetensors=True)\n",
        "\n",
        "    # load quantized model, currently only support cpu or single gpu\n",
        "    model = GPTQModel.from_quantized(quantized_model_id, device=\"cuda:0\")\n",
        "\n",
        "    # inference with model.generate\n",
        "    print(tokenizer.decode(model.generate(**tokenizer(\"What is the capital of Jamaica?\", return_tensors=\"pt\").to(\"cuda:0\"))[0]))\n",
        "\n",
        "    print(f\"Quantized Model {quantized_model_id} avg PPL is {calculate_avg_ppl(model, tokenizer)}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import logging\n",
        "\n",
        "    logging.basicConfig(\n",
        "        format=\"%(asctime)s %(levelname)s [%(name)s] %(message)s\",\n",
        "        level=logging.INFO,\n",
        "        datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
        "    )\n",
        "\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "4sJBhYRZm3YT",
        "outputId": "cf980252-c5e6-430c-d8ff-e5000872bcde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'gptqmodel'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-105429da677d>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgptqmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGPTQModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQuantizeConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gptqmodel'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    }
  ]
}